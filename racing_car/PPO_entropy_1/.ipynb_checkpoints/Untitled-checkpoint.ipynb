{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f67607b-5a24-46bf-8430-bcc602d7b80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swig in e:\\anaconda\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: gymnasium[box2d] in e:\\anaconda\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in e:\\anaconda\\lib\\site-packages (from gymnasium[box2d]) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in e:\\anaconda\\lib\\site-packages (from gymnasium[box2d]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in e:\\anaconda\\lib\\site-packages (from gymnasium[box2d]) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in e:\\anaconda\\lib\\site-packages (from gymnasium[box2d]) (0.0.4)\n",
      "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
      "  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pygame>=2.1.3 in e:\\anaconda\\lib\\site-packages (from gymnasium[box2d]) (2.6.1)\n",
      "Requirement already satisfied: swig==4.* in e:\\anaconda\\lib\\site-packages (from gymnasium[box2d]) (4.3.0)\n",
      "Building wheels for collected packages: box2d-py\n",
      "  Building wheel for box2d-py (setup.py): started\n",
      "  Building wheel for box2d-py (setup.py): finished with status 'done'\n",
      "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp312-cp312-win_amd64.whl size=463082 sha256=71207dbfccbaa49c538bd39b1345bd6110ad4699956344bd69f7a35d0596c5ab\n",
      "  Stored in directory: c:\\users\\papa\\appdata\\local\\pip\\cache\\wheels\\2a\\e9\\60\\774da0bcd07f7dc7761a8590fa2d065e4069568e78dcdc3318\n",
      "Successfully built box2d-py\n",
      "Installing collected packages: box2d-py\n",
      "Successfully installed box2d-py-2.3.5\n"
     ]
    }
   ],
   "source": [
    "!pip install swig\n",
    "!pip install gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc77c49e-bf66-494a-8c39-fa3e058de839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training PPO on CarRacing: 100%|██████████████████████████████████████████████████| 100/100 [6:28:05<00:00, 232.86s/it]\n",
      "E:\\Anaconda\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 540.74 ± 322.95\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import VecTransposeImage, DummyVecEnv\n",
    "from tqdm import trange\n",
    "import os\n",
    "\n",
    "SEED = 42\n",
    "log_dir = \"./ppo_carracing_tensorboard/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "def make_env():\n",
    "    env = gym.make(\"CarRacing-v3\", render_mode=\"rgb_array\", continuous=True)\n",
    "    env.reset(seed=SEED)\n",
    "    env.action_space.seed(SEED)\n",
    "    return env\n",
    "\n",
    "env = DummyVecEnv([make_env])\n",
    "env = VecTransposeImage(env)\n",
    "\n",
    "model = PPO(\n",
    "    \"CnnPolicy\",\n",
    "    env,\n",
    "    seed=SEED,\n",
    "    verbose=0,\n",
    "    learning_rate=0.0001,\n",
    "    gamma=0.99,\n",
    "    ent_coef=0.01,\n",
    "    tensorboard_log=log_dir\n",
    ")\n",
    "\n",
    "total_timesteps = 1_000_000  \n",
    "chunk_size = 10000\n",
    "\n",
    "with trange(0, total_timesteps, chunk_size, desc=\"Training PPO on CarRacing\") as pbar:\n",
    "    for _ in pbar:\n",
    "        model.learn(total_timesteps=chunk_size, reset_num_timesteps=False, tb_log_name=\"PPO_CarRacing_Entropy\")\n",
    "\n",
    "model.save(\"ppo_carracing_sb3\")\n",
    "\n",
    "model = PPO.load(\"ppo_carracing_sb3\", env=env)\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=5, render=True, deterministic=True)\n",
    "print(f\"Mean reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a770769e-150d-43d9-9623-e3e8e4471978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall average across seeds: Mean reward = 687.34 ± 239.11\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecTransposeImage\n",
    "import numpy as np\n",
    "\n",
    "seeds = [0, 1, 10, 42, 100, 123, 999]\n",
    "n_eval_episodes = 5\n",
    "\n",
    "def make_env(seed):\n",
    "    def _init():\n",
    "        env = gym.make(\"CarRacing-v3\", render_mode=\"rgb_array\", continuous=True)\n",
    "        env.reset(seed=seed)\n",
    "        env.action_space.seed(seed)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "mean_rewards = []\n",
    "std_rewards = []\n",
    "\n",
    "for seed in seeds:\n",
    "    vec_env = DummyVecEnv([make_env(seed)])\n",
    "    vec_env = VecTransposeImage(vec_env)\n",
    "    model = PPO.load(\"ppo_carracing_sb3\", env=vec_env)\n",
    "    mean_reward, std_reward = evaluate_policy(\n",
    "        model, vec_env, n_eval_episodes=n_eval_episodes, render=False, deterministic=False\n",
    "    )\n",
    "    mean_rewards.append(mean_reward)\n",
    "    std_rewards.append(std_reward)\n",
    "\n",
    "overall_mean = np.mean(mean_rewards)\n",
    "overall_std = np.mean(std_rewards)\n",
    "\n",
    "print(f\"\\nOverall average across seeds: Mean reward = {overall_mean:.2f} ± {overall_std:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84761374-3ad1-4f33-aecf-e6bb57dd5b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 reward: 55.48\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     23\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 24\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.03\u001b[39m)  \n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_reward\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecTransposeImage, DummyVecEnv\n",
    "import time\n",
    "\n",
    "def make_env():\n",
    "    env = gym.make(\"CarRacing-v3\", render_mode=\"human\", continuous=True)  # human mode = display in real time\n",
    "    return env\n",
    "\n",
    "env = DummyVecEnv([make_env])\n",
    "env = VecTransposeImage(env)\n",
    "model = PPO.load(\"ppo_carracing_sb3\", env=env)\n",
    "\n",
    "n_episodes = 5\n",
    "for ep in range(n_episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward[0]\n",
    "        time.sleep(0.03)  \n",
    "\n",
    "    print(f\"Episode {ep + 1} reward: {total_reward:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1714b5-95f7-4526-bfc4-92a1d7723f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
